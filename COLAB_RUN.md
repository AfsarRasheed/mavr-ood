# MAVR-OOD: Google Colab Implementation Guide
> Complete step-by-step cells to run the multi-agent OOD detection pipeline on Google Colab (T4 GPU)
>
> **Tested:** Feb 2026 | **Runtime:** T4 GPU | **Results:** mIoU 0.97, F1 0.99 on test image

---

## Phase 1: Setup (Run once per session)

### Cell 1 â€” Clone Repository (first time only)
```python
# First time: clone the repo
!git clone https://github.com/AfsarRasheed/mavr-ood.git
%cd mavr-ood

# Returning session: just pull latest
# %cd mavr-ood
# !git checkout -- .
# !git pull origin main
```

### Cell 2 â€” Install Dependencies
> âš ï¸ **Run this every new Colab session** â€” Colab resets packages on runtime restart.
```python
!pip install -q -r requirements.txt
!pip install -q gradio>=4.0.0 addict yapf bitsandbytes>=0.41.0
!pip install -q -e segment_anything/
!cd GroundingDINO && pip install -q -e . && cd ..

# Verify critical packages
import torch, bitsandbytes
print(f"âœ… torch {torch.__version__}, CUDA: {torch.cuda.is_available()}")
print(f"âœ… bitsandbytes installed (4-bit quantization enabled)")
print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
print(f"âœ… VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB")
print("âœ… All dependencies installed!")
```

### Cell 3 â€” Download Weights (~3 min, first time only)
```python
import os
if not os.path.exists("weights/groundingdino_swint_ogc.pth"):
    !mkdir -p weights
    !wget -q -P weights/ https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth
    !wget -q -P weights/ https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth
    print("âœ… Weights downloaded!")
else:
    print("âœ… Weights already exist!")
```

---

## Phase 2A: Single Image Test (Quick validation ~15 min)

### Cell 4A â€” Prepare Single Image Test
```python
!mkdir -p ./data/test_single/original
!mkdir -p ./data/test_single/labels
!cp ./data/challenging_subset/original/animals03_Zebras_in_the_road.jpg ./data/test_single/original/
!cp ./data/challenging_subset/labels/animals03_Zebras_in_the_road.png ./data/test_single/labels/
print("âœ… Test folder ready (1 image)")
```

### Cell 5A â€” Run All 5 Agents (~12 min)
> Each agent loads LLaVA-7B (4-bit quantized, ~4GB VRAM) and analyzes the image.
```python
!python src/agents/run_all_agents.py \
    --image_dir ./data/test_single/original \
    --output_dir ./outputs/test_single_prompts \
    --delay 2
```

### Cell 6A â€” Run Evaluation (GroundingDINO + CLIP + SAM)
```python
!python run_evaluate.py \
    --config GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py \
    --grounded_checkpoint weights/groundingdino_swint_ogc.pth \
    --sam_checkpoint weights/sam_vit_h_4b8939.pth \
    --dataset_dir ./data/test_single \
    --dataset_type road_anomaly \
    --multiagent_prompts ./outputs/test_single_prompts/agent5_final_synthesis_results.json \
    --output_dir ./outputs/test_single_results \
    --clip_threshold 0.20 \
    --device cuda
```

### Cell 7A â€” View Results & Agent Reasoning
```python
from IPython.display import display, Image as IPImage
import glob, os, json

# Show metrics
with open("outputs/test_single_results/multiagent_evaluation_results.json") as f:
    results = json.load(f)
    m = results["average_metrics"]
    print(f"ğŸ“Š mIoU: {m['mIoU']:.4f} | F1: {m['F1']:.4f} | Precision: {m['Precision']:.4f} | Recall: {m['Recall']:.4f}")
    print(f"ğŸ“Š Detection Rate: {results['detection_rate']}%\n")

# Show agent reasoning
with open("outputs/test_single_prompts/agent5_final_synthesis_results.json") as f:
    agent5 = json.load(f)
    for r in agent5.get("results", []):
        img = r.get("image", "")
        syn = r.get("synthesis_result", {})
        prompts = syn.get("grounded_sam_prompts", {})
        print(f"\nğŸ¤– {img}")
        print(f"   Prompt V1: {prompts.get('prompt_v1', 'N/A')}")
        print(f"   Prompt V2: {prompts.get('prompt_v2', 'N/A')}")
        print(f"   Confidence: {syn.get('overall_confidence', 'N/A')}")
        print(f"   Anomaly Type: {syn.get('anomaly_type', 'N/A')}")
        print(f"   Reasoning: {syn.get('reasoning', 'N/A')}")

# Show visualizations
print("\n" + "="*60)
for r in sorted(glob.glob("outputs/test_single_results/*.jpg")):
    print(f"ğŸ“· {os.path.basename(r)}")
    display(IPImage(r, width=600))
```

---

## Phase 2B: Full Dataset Run (13 images, ~60 min)

### Cell 4B â€” Run All Agents on Full Dataset (~45 min)
```python
!python src/agents/run_all_agents.py \
    --image_dir ./data/challenging_subset/original \
    --output_dir ./outputs/challenging_subset_prompts \
    --delay 2
```

### Cell 5B â€” Evaluate Full Dataset
```python
!python run_evaluate.py \
    --config GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py \
    --grounded_checkpoint weights/groundingdino_swint_ogc.pth \
    --sam_checkpoint weights/sam_vit_h_4b8939.pth \
    --dataset_dir ./data/challenging_subset \
    --dataset_type road_anomaly \
    --multiagent_prompts ./outputs/challenging_subset_prompts/agent5_final_synthesis_results.json \
    --output_dir ./outputs/evaluation_results \
    --clip_threshold 0.20 \
    --device cuda
```

### Cell 6B â€” View All Results & Agent Reasoning
```python
from IPython.display import display, Image as IPImage
import glob, os, json

# Metrics
with open("outputs/evaluation_results/multiagent_evaluation_results.json") as f:
    results = json.load(f)
    m = results["average_metrics"]
    print(f"ğŸ“Š mIoU: {m['mIoU']:.4f} | F1: {m['F1']:.4f} | Precision: {m['Precision']:.4f} | Recall: {m['Recall']:.4f}")
    print(f"ğŸ“Š Detection Rate: {results['detection_rate']}%")

# Agent reasoning per image
with open("outputs/challenging_subset_prompts/agent5_final_synthesis_results.json") as f:
    agent5 = json.load(f)
    print(f"\n{'='*60}")
    print("ğŸ¤– AGENT REASONING")
    print(f"{'='*60}")
    for r in agent5.get("results", []):
        img = r.get("image", "")
        syn = r.get("synthesis_result", {})
        prompts = syn.get("grounded_sam_prompts", {})
        print(f"\nğŸ“¸ {img}")
        print(f"   V1: {prompts.get('prompt_v1', 'N/A')} | V2: {prompts.get('prompt_v2', 'N/A')}")
        print(f"   Confidence: {syn.get('overall_confidence', 'N/A')} | Type: {syn.get('anomaly_type', 'N/A')}")
        print(f"   Reasoning: {syn.get('reasoning', 'N/A')[:200]}")

# Visualizations
print(f"\n{'='*60}")
for r in sorted(glob.glob("outputs/evaluation_results/*.jpg")):
    print(f"\nğŸ“· {os.path.basename(r)}")
    display(IPImage(r, width=600))
```

---

## Phase 3: Gradio App (Optional)

### Cell â€” Launch Gradio App
```python
import app
demo = app.build_app()
demo.launch(share=True)
```

---

## Troubleshooting

| Error | Fix |
|-------|-----|
| `CUDA out of memory` | Ensure `bitsandbytes` is installed: `!pip install -q bitsandbytes>=0.41.0` |
| `No module named 'addict'` | Run Cell 2 again |
| `cannot import sam_model_registry` | Run `!pip install -q -e segment_anything/` |
| `get_extended_attention_mask` TypeError | Already fixed in `run_evaluate.py` â€” just `!git pull origin main` |
| Session disconnects | Re-run from Cell 2 (deps), Cell 3 will skip if weights exist |
| Agent JSON parsing failed | Non-critical â€” Agent 5 still synthesizes from raw output |
| `git pull` blocked by local changes | Run `!git checkout -- .` then `!git pull origin main` |

---

## Architecture Overview

```
Image â†’ Agent 1 (Scene Context)     â”€â”
      â†’ Agent 2 (Spatial Anomaly)    â”€â”¤
      â†’ Agent 3 (Semantic Analysis)  â”€â”¼â†’ Agent 5 (Synthesis) â†’ prompt_v1, prompt_v2
      â†’ Agent 4 (Visual Appearance)  â”€â”˜           â†“
                                         GroundingDINO (detection)
                                              â†“
                                         CLIP (verification)
                                              â†“
                                         SAM (segmentation)
                                              â†“
                                         Evaluation (mIoU, F1)
```
