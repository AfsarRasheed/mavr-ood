# Core
torch
torchvision
numpy
Pillow
opencv-python
matplotlib
scikit-learn
tqdm

# VLM Backend (LLaVA-7B)
transformers>=4.36.0
accelerate>=0.25.0
bitsandbytes>=0.41.0

# CLIP Verification
git+https://github.com/openai/CLIP.git

# GroundingDINO & SAM
supervision

# Utilities
python-dotenv
requests
gradio>=4.0.0